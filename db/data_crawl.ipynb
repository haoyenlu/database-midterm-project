{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577bc78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API key:AIzaSyDtNWOeaOYwfSa8sQiPNIQJmj2c-Bf_83E\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import googlemaps\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import pinyin\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from googlemaps import *\n",
    "from os.path import join, dirname\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36'}\n",
    "\n",
    "#google api key for GEOCODING and PLACES\n",
    "API_KEY = input(\"Google API key:\")\n",
    "\n",
    "#確認spots.csv在同一目錄下\n",
    "#讀取非浪點資料\n",
    "beach94 = []\n",
    "\n",
    "with open('./spots.csv', newline='',encoding=\"utf-8\") as csvfile:\n",
    "    \n",
    "    rows = csv.reader(csvfile)\n",
    "    firstRow = True;    \n",
    "    for row in rows:\n",
    "        if firstRow == True:\n",
    "            firstRow = False\n",
    "            continue\n",
    "        beach94.append(row)\n",
    "\n",
    "#取得浪點LIST\n",
    "url = 'https://swelleye.com/surf-forecasts/'\n",
    "resp = requests.get(url)\n",
    "resp.encoding='utf-8' \n",
    "soup = BeautifulSoup(resp.text)\n",
    "\n",
    "#浪點英文名\n",
    "spot_list = []\n",
    "#浪點中文名\n",
    "chi_list = []\n",
    "\n",
    "for i in soup.find_all(\"a\", class_=\"list-link\"):\n",
    "    name_href = i['href']\n",
    "    chi_name = i.text\n",
    "    \n",
    "    name = name_href[12:(len(name_href)-14)]\n",
    "    spot_list.append(name)\n",
    "    chi_list.append(chi_name[29:(len(chi_name)-25)])\n",
    "    \n",
    "#取得浪點經緯度\n",
    "lon_list = []\n",
    "lat_list = []\n",
    "\n",
    "for spot_name in spot_list:\n",
    "    spot_url = \"https://swelleye.com/surf-spots/\" + spot_name + \"/#surf-forecast\"\n",
    "    resp = requests.get(spot_url)\n",
    "    resp.encoding='utf-8' \n",
    "    soup = BeautifulSoup(resp.text)\n",
    "    geo_url = soup.find(\"iframe\", height=\"570px\")['src']\n",
    "    lat = float( geo_url[(geo_url.find('=')+1):geo_url.find('&')] )\n",
    "    lon = float( geo_url[(geo_url.find( '=', geo_url.find('=')+1 )+1):geo_url.find('&', geo_url.find('&')+1)] )\n",
    "    lat_list.append(lat)\n",
    "    lon_list.append(lon)\n",
    "\n",
    "#取得浪點所在鄉鎮資料\n",
    "spot_town = []\n",
    "\n",
    "key = API_KEY\n",
    "for i in range(len(spot_list)):\n",
    "    resp = requests.get('http://api.opencube.tw/location?lat='+str(lat_list[i])+'&lng='+str(lon_list[i])+'&key='+key)\n",
    "    rjson = json.loads(resp.text)\n",
    "    spot_town.append(rjson[\"data\"][\"district\"])\n",
    "\n",
    "#取得縣市list\n",
    "city_url = \"https://api.nlsc.gov.tw/other/ListCounty\"\n",
    "resp = requests.get(city_url)\n",
    "soup = BeautifulSoup(resp.text)\n",
    "city_list = []\n",
    "city_id = []\n",
    "for i in soup.find_all('countyname'):\n",
    "    city_list.append(i.text)\n",
    "for i in soup.find_all('countycode'):\n",
    "    city_id.append(i.text)\n",
    "\n",
    "#取得鄉鎮list\n",
    "town_list = []\n",
    "town_id = []\n",
    "town_loc_city = []\n",
    "for i in range(len(city_id)):\n",
    "    town_url = \"https://api.nlsc.gov.tw/other/ListTown/\" + city_id[i]\n",
    "    resp = requests.get(town_url)\n",
    "    soup = BeautifulSoup(resp.text)\n",
    "    for k in soup.find_all('townname'):\n",
    "        town_list.append(k.text)\n",
    "    for j in soup.find_all('towncode'):\n",
    "        town_id.append(j.text)\n",
    "        town_loc_city.append(city_list[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1bd949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#取得商店資訊\n",
    "\n",
    "gmaps = googlemaps.Client(key = API_KEY)\n",
    "\n",
    "shop_name_list = []\n",
    "shop_spot_list = []\n",
    "shop_rating_list = []\n",
    "shop_open_list = []\n",
    "shop_address_list = []\n",
    "\n",
    "for i in range(len(spot_list)):\n",
    "    loc = {'lat':lat_list[i], 'lng':lon_list[i]}\n",
    "    output = gmaps.places_nearby(keyword=\"衝浪\", location = loc, radius = 500)['results']\n",
    "    for j in range(len(output)):\n",
    "        if(j<5):\n",
    "            shop_name_list.append(output[j]['name'])\n",
    "            shop_rating_list.append(output[j]['rating'])\n",
    "            shop_address_list.append(output[j]['vicinity'])\n",
    "            if('opening_hours' in output[j].keys()):\n",
    "                if('open_now' in output[j]['opening_hours'].keys()):\n",
    "                    shop_open_list.append(output[j]['opening_hours']['open_now'])\n",
    "                else:\n",
    "                    shop_open_list.append(None)\n",
    "            else:\n",
    "                shop_open_list.append(None)\n",
    "            shop_spot_list.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44a8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#取得新聞資料\n",
    "news_title_list = []\n",
    "news_url_list = []\n",
    "news_spot_list = []\n",
    "news_time_list = []\n",
    "\n",
    "for i in range(len(chi_list)):\n",
    "    url = 'https://news.google.com/search?q='+chi_list[i]+'衝浪&hl=zh-TW&gl=TW&ceid=TW%3Azh-Hant'\n",
    "    resp = requests.get(url)\n",
    "    resp.encoding='utf-8' \n",
    "    soup = BeautifulSoup(resp.text)\n",
    "    for j in soup.find_all(\"a\", class_=\"DY5T1d RZIKme\")[0:5]:\n",
    "        \n",
    "        news_title_list.append(j.text)\n",
    "        news_spot_list.append(i+1)\n",
    "        url = 'https://news.google.com'+ j['href'][1:]\n",
    "        news_url_list.append(url)\n",
    "        \n",
    "        resp = requests.get(url)\n",
    "        resp.encoding='utf-8' \n",
    "        if(soup.find(\"time\")):\n",
    "            k = soup.find(\"time\")\n",
    "            news_time_list.append(str(k.text).replace(' ', ''))\n",
    "        else:\n",
    "            news_time_list.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c67860a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - \n",
      "\n",
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 96.0.4664\n",
      "[WDM] - Get LATEST driver version for 96.0.4664\n",
      "[WDM] - Driver [C:\\Users\\linyf\\.wdm\\drivers\\chromedriver\\win32\\96.0.4664.45\\chromedriver.exe] found in cache\n",
      "<ipython-input-4-376fc77ab154>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"forecast\"]/div[1]/a[1]/div[1]/div[1]\"}\n  (Session info: chrome=96.0.4664.45)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00C56903+2517251]\n\tOrdinal0 [0x00BEF8E1+2095329]\n\tOrdinal0 [0x00AF2848+1058888]\n\tOrdinal0 [0x00B1D448+1233992]\n\tOrdinal0 [0x00B1D63B+1234491]\n\tOrdinal0 [0x00B47812+1406994]\n\tOrdinal0 [0x00B3650A+1336586]\n\tOrdinal0 [0x00B45BBF+1399743]\n\tOrdinal0 [0x00B3639B+1336219]\n\tOrdinal0 [0x00B127A7+1189799]\n\tOrdinal0 [0x00B13609+1193481]\n\tGetHandleVerifier [0x00DE5904+1577972]\n\tGetHandleVerifier [0x00E90B97+2279047]\n\tGetHandleVerifier [0x00CE6D09+534521]\n\tGetHandleVerifier [0x00CE5DB9+530601]\n\tOrdinal0 [0x00BF4FF9+2117625]\n\tOrdinal0 [0x00BF98A8+2136232]\n\tOrdinal0 [0x00BF99E2+2136546]\n\tOrdinal0 [0x00C03541+2176321]\n\tBaseThreadInitThunk [0x74ECFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77057A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77057A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-376fc77ab154>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#print(spot_list[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'//*[@id=\"forecast\"]/div[1]/a['\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m']/div[1]/div[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;31m#12個時段\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1236\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1238\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m   1239\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    420\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"forecast\"]/div[1]/a[1]/div[1]/div[1]\"}\n  (Session info: chrome=96.0.4664.45)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00C56903+2517251]\n\tOrdinal0 [0x00BEF8E1+2095329]\n\tOrdinal0 [0x00AF2848+1058888]\n\tOrdinal0 [0x00B1D448+1233992]\n\tOrdinal0 [0x00B1D63B+1234491]\n\tOrdinal0 [0x00B47812+1406994]\n\tOrdinal0 [0x00B3650A+1336586]\n\tOrdinal0 [0x00B45BBF+1399743]\n\tOrdinal0 [0x00B3639B+1336219]\n\tOrdinal0 [0x00B127A7+1189799]\n\tOrdinal0 [0x00B13609+1193481]\n\tGetHandleVerifier [0x00DE5904+1577972]\n\tGetHandleVerifier [0x00E90B97+2279047]\n\tGetHandleVerifier [0x00CE6D09+534521]\n\tGetHandleVerifier [0x00CE5DB9+530601]\n\tOrdinal0 [0x00BF4FF9+2117625]\n\tOrdinal0 [0x00BF98A8+2136232]\n\tOrdinal0 [0x00BF99E2+2136546]\n\tOrdinal0 [0x00C03541+2176321]\n\tBaseThreadInitThunk [0x74ECFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77057A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77057A6E+238]\n"
     ]
    }
   ],
   "source": [
    "#獲取浪點預報\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "info_spot_id = []\n",
    "info_date = []\n",
    "wave_height = []\n",
    "wave_period = []\n",
    "wave_dir = []\n",
    "wind_speed = []\n",
    "wind_dir = []\n",
    "temp = []\n",
    "sea_temp = []\n",
    "\n",
    "today = datetime.today()\n",
    "for i in range(len(spot_list)):\n",
    "    url = \"https://swelleye.com/surf-spots/\" + spot_list[i] + \"/#surf-forecast\"\n",
    "    driver.get(url)\n",
    "    xf = driver.find_element(By.XPATH, '//*[@id=\"surf-forecast\"]/div[2]/div[1]/iframe')\n",
    "    driver.switch_to.frame(xf)\n",
    "    #7天預報\n",
    "    #print(spot_list[i])\n",
    "    for j in range(6):\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"forecast\"]/div[1]/a[' + str(j+1) + ']/div[1]/div[1]').click()\n",
    "        #12個時段\n",
    "        for k in range(11):\n",
    "            #浪點\n",
    "            info_spot_id.append(i+1)\n",
    "            pred_day = today + timedelta(days=j)\n",
    "            info_date.append(pred_day.strftime('%Y-%m-%d') + f\" {k*2:02d}\")\n",
    "            #浪高(m)\n",
    "            wave_height.append(driver.find_element(By.XPATH, '//*[@id=\"forecast-content\"]/div[' + str(j+1) + ']/div/div[2]/div[' + str(k+1) + ']/span[1]').text)\n",
    "            #浪週期(s)\n",
    "            wave_period.append(driver.find_element(By.XPATH, '//*[@id=\"forecast-content\"]/div[' + str(j+1) + ']/div/div[3]/span[' + str(k+1) + ']').text)\n",
    "            #浪向(。)\n",
    "            wave_dir.append( re.sub(\"[^0-9]\", \"\",str(driver.find_element(By.XPATH, '//*[@id=\"forecast-content\"]/div[' + str(j+1) + ']/div/div[4]/div[' + str(k+1) + ']/div/div').get_attribute('class'))) )\n",
    "            #風力(m/s)\n",
    "            wind_speed.append(driver.find_element(By.XPATH, '//*[@id=\"forecast-content\"]/div[' + str(j+1) + ']/div/div[5]/div[' + str(k+1) + ']/span[1]').text)\n",
    "            #風向(。)\n",
    "            wind_dir.append( re.sub(\"[^0-9]\", \"\",str(driver.find_element(By.XPATH, '//*[@id=\"forecast-content\"]/div[' + str(j+1) + ']/div/div[6]/div[' + str(k+1) + ']/div/div').get_attribute('class'))) )\n",
    "            #溫度(。C)\n",
    "            temp.append(driver.find_element(By.XPATH, '//*[@id=\"forecast-content\"]/div[' + str(j+1) + ']/div/div[9]/div[' + str(k+1) + ']/span[1]').text)\n",
    "            #海溫(。C)\n",
    "            sea_temp.append(driver.find_element(By.XPATH, '//*[@id=\"forecast-content\"]/div[' + str(j+1) + ']/div/div[10]/div[' + str(k+1) + ']/span[1]').text)   \n",
    "    driver.switch_to.default_content()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d385cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Town Table\n",
    "df_town = pd.DataFrame(list(zip(town_id, town_list,town_loc_city)), columns =['Id','Name', 'City'])\n",
    "df_town['Name'] = df_town['Name'].str.replace('臺','台')\n",
    "df_town['City'] = df_town['City'].str.replace('臺','台')\n",
    "\n",
    "#Type Table\n",
    "df_type = pd.DataFrame([[1, '浪點'], [2, '海水浴場'], [3, '海灘'], [4, '其他']], columns = ['Id', 'Name'])\n",
    "\n",
    "#Spot Table\n",
    "type_list = [1]*len(chi_list)\n",
    "spot_town_id = []\n",
    "other_town_id = []\n",
    "for i in spot_town:\n",
    "    if i is None:\n",
    "        spot_town_id.append(None)\n",
    "    else:\n",
    "        spot_town_id.append(df_town.loc[df_town.Name == i, 'Id'].values[0])\n",
    "\n",
    "df_other = pd.DataFrame(beach94, columns = ['Name', 'Lon', 'Lat', 'Town', 'County', 'index'])\n",
    "for i in df_other.itertuples(index=False):\n",
    "    value_id = df_town.loc[df_town.Name == i.Town, 'Id'].values\n",
    "    if(len(value_id) == 0):\n",
    "        other_town_id.append(None)\n",
    "    elif(len(value_id) == 1):\n",
    "        other_town_id.append(value_id[0])\n",
    "    else:\n",
    "        found = False\n",
    "        for j in value_id:\n",
    "            if(df_town.loc[df_town.Id == j, 'City'].values[0] == i.County):\n",
    "                other_town_id.append(j)\n",
    "                found = True\n",
    "                break\n",
    "        if(found == False):\n",
    "            other_town_id.append(None)\n",
    "type_other = []\n",
    "for i in beach94:\n",
    "    if '灘' in i[0]:\n",
    "        type_other.append(3)\n",
    "    elif '浴場' in i[0]:\n",
    "        type_other.append(2)\n",
    "    else:\n",
    "        type_other.append(4)\n",
    "df_other['Town_id'] = other_town_id\n",
    "df_other['Type_id'] = type_other\n",
    "\n",
    "df_spot = pd.DataFrame(list(zip(chi_list, lon_list,lat_list,spot_town_id, type_list)), columns =['Name', 'Lon', 'Lat', 'Town_id', 'Type_id'])\n",
    "df_other2 = df_other[['Name', 'Lon', 'Lat', 'Town_id', 'Type_id']]\n",
    "df_spot = df_spot.append(df_other2, ignore_index = True)\n",
    "df_spot['Id'] = df_spot.index+1\n",
    "\n",
    "#Surfshop Table\n",
    "df_surfshop = pd.DataFrame(list(zip(shop_name_list, shop_address_list,shop_spot_list,shop_rating_list, shop_open_list)), columns =['Name', 'Address', 'Spot_id', 'Rating', 'Operating_now'])\n",
    "df_surfshop['Id'] = df_surfshop.index+1\n",
    "\n",
    "#News Table\n",
    "df_news = pd.DataFrame(list(zip(news_time_list, news_url_list,news_title_list,news_spot_list)), columns =['Date', 'Url', 'Title', 'Spot_id'])\n",
    "df_news['Id'] = df_news.index+1\n",
    "\n",
    "#Information Table\n",
    "df_information = pd.DataFrame(list(zip(info_spot_id, info_date,\n",
    "                                       wave_height, wave_period, wave_dir,\n",
    "                                       wind_speed, wind_dir,\n",
    "                                       temp, sea_temp)), columns =['Spot_id', 'Date', 'Wave_height', 'Wave_period', 'Wave_direction', 'Wind_speed', 'Wind_direction', 'Temperature', 'Sea_temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc624b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用 Google API 進行評論爬蟲\n",
    "\n",
    "total_reviewers = []\n",
    "total_reviews = []\n",
    "\n",
    "for place in df_spot.itertuples(index=False):\n",
    "    geocode_result = gmaps.geocode(place.Name)\n",
    "    loc = geocode_result[0]['place_id']\n",
    "    try:\n",
    "        reference_review = gmaps.place(place_id = loc, language = 'zh-TW')['result']['reviews']\n",
    "        for i in range(3):\n",
    "            try:\n",
    "                review = []\n",
    "                reviewer = []\n",
    "                review.append(place.Id)\n",
    "                review.append(reference_review[i]['author_name'])\n",
    "                review.append(reference_review[i]['rating'])\n",
    "                review.append(reference_review[i]['text'])\n",
    "                review.append(reference_review[i]['time'])\n",
    "\n",
    "                reviewer.append(reference_review[i]['author_name'])\n",
    "                reviewer.append(pinyin.get(reference_review[i]['author_name'], format = \"numerical\") + \"@gmail.com\")\n",
    "                total_reviewers.append(reviewer)\n",
    "                total_reviews.append(review)\n",
    "            except:\n",
    "                break\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviewer Table\n",
    "df_reviewer = pd.DataFrame(total_reviewers, columns =['Name', 'Email'])\n",
    "df_reviewer = df_reviewer.drop_duplicates(ignore_index = True)\n",
    "df_reviewer['Id'] = df_reviewer.index+1\n",
    "\n",
    "#Recommend Table\n",
    "df_recommend = pd.DataFrame(total_reviews, columns =['Spot_id', 'Reviewer', 'Score', 'Content', 'Date'])\n",
    "rec_reviewer_id = []\n",
    "for i in df_recommend.Reviewer:\n",
    "    rec_reviewer_id.append(df_reviewer.loc[df_reviewer.Name == i, 'Id'].values[0])\n",
    "df_recommend['Reviewer_id'] = rec_reviewer_id\n",
    "rec_timestamp = df_recommend['Date']\n",
    "rec_dt = map(lambda x: (datetime.fromtimestamp(x)).strftime('%Y-%m-%d'), rec_timestamp)\n",
    "df_recommend['Date'] = list(rec_dt)\n",
    "df_recommend.drop(columns=[\"Reviewer\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in your db account info\n",
    "username = input(\"Username:\")\n",
    "password = input(\"Password:\")\n",
    "\n",
    "#username = 'postgres'\n",
    "#password = \n",
    "# let's insert data\n",
    "engine = create_engine(\"postgresql://\" + username + \":\" + password + \"@localhost:5432/SURF\")\n",
    "df_type.to_sql('TYPE', engine, schema = 'SURF', if_exists=\"append\", index = False)\n",
    "df_town.to_sql('TOWN', engine, schema = 'SURF', if_exists=\"append\", index = False)\n",
    "df_spot.to_sql('SPOT', engine, schema = 'SURF', if_exists=\"append\", index = False)\n",
    "df_surfshop.to_sql('SURFSHOP', engine, schema = 'SURF', if_exists=\"append\", index = False)\n",
    "df_information.to_sql('INFORMATION', engine, schema = 'SURF', if_exists=\"append\", index = False)\n",
    "df_news.to_sql('NEWS', engine, schema = 'SURF', if_exists=\"append\", index = False)\n",
    "df_reviewer.to_sql('REVIEWER', engine, schema = 'SURF', if_exists=\"append\", index = False)\n",
    "df_recommend.to_sql('RECOMMEND', engine, schema = 'SURF', if_exists=\"append\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6af1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901d847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c08417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
